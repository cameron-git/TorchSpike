{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\"if True else \"cpu\")\n",
    "runs = 100\n",
    "neurons = [1024, 2048, 4096, 8192, 16384]\n",
    "x = torch.randn(500, 16, neurons[3], requires_grad=True).to(device)\n",
    "# x = torch.randn(8, 1, 4, requires_grad=True).to(device)\n",
    "x.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13817385927999568,\n",
       " 2001.5,\n",
       " tensor([[[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([[[2.8896e-09, 2.6979e-09, 1.6111e-09,  ..., 2.8149e-09,\n",
       "           3.0786e-09, 2.9041e-09],\n",
       "          [3.0045e-09, 2.8988e-09, 2.3646e-09,  ..., 2.5774e-09,\n",
       "           3.1321e-09, 3.1155e-09],\n",
       "          [2.6586e-09, 3.1333e-09, 2.2385e-09,  ..., 2.8375e-09,\n",
       "           3.0753e-09, 3.1960e-09],\n",
       "          ...,\n",
       "          [3.0059e-09, 2.5287e-09, 3.1014e-09,  ..., 2.8251e-09,\n",
       "           2.4322e-09, 2.9495e-09],\n",
       "          [2.7140e-09, 2.7077e-09, 2.4722e-09,  ..., 2.6858e-09,\n",
       "           2.7937e-09, 3.0637e-09],\n",
       "          [2.5323e-09, 3.0917e-09, 2.7463e-09,  ..., 3.1273e-09,\n",
       "           2.2244e-09, 2.7691e-09]],\n",
       " \n",
       "         [[2.5290e-09, 2.1875e-09, 2.2559e-09,  ..., 2.6415e-09,\n",
       "           3.0522e-09, 2.5998e-09],\n",
       "          [2.9778e-09, 2.7247e-09, 1.3504e-09,  ..., 2.5089e-09,\n",
       "           3.1511e-09, 2.9949e-09],\n",
       "          [2.9623e-09, 3.1400e-09, 2.3068e-09,  ..., 2.5998e-09,\n",
       "           3.1013e-09, 3.1843e-09],\n",
       "          ...,\n",
       "          [2.9715e-09, 2.8737e-09, 2.9732e-09,  ..., 2.8664e-09,\n",
       "           2.6944e-09, 2.9461e-09],\n",
       "          [2.8926e-09, 2.2341e-09, 2.3769e-09,  ..., 2.7142e-09,\n",
       "           3.0711e-09, 2.9595e-09],\n",
       "          [2.7989e-09, 3.0138e-09, 2.7261e-09,  ..., 3.0236e-09,\n",
       "           2.2933e-09, 3.0541e-09]],\n",
       " \n",
       "         [[1.6310e-09, 2.5317e-09, 2.7812e-09,  ..., 2.9149e-09,\n",
       "           2.9434e-09, 2.1847e-09],\n",
       "          [3.1590e-09, 2.8528e-09, 2.9598e-09,  ..., 2.1753e-09,\n",
       "           3.1228e-09, 2.8827e-09],\n",
       "          [3.1449e-09, 3.1094e-09, 2.5441e-09,  ..., 2.2767e-09,\n",
       "           3.0059e-09, 3.1625e-09],\n",
       "          ...,\n",
       "          [2.9441e-09, 3.1326e-09, 2.7620e-09,  ..., 2.4138e-09,\n",
       "           2.9502e-09, 2.9427e-09],\n",
       "          [2.7468e-09, 2.1021e-09, 2.3648e-09,  ..., 2.5846e-09,\n",
       "           3.1198e-09, 3.0912e-09],\n",
       "          [2.5560e-09, 2.9829e-09, 2.8700e-09,  ..., 2.8264e-09,\n",
       "           2.2289e-09, 2.8557e-09]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[2.7764e-09, 2.5188e-09, 2.1556e-09,  ..., 2.4090e-09,\n",
       "           2.8864e-09, 2.4984e-09],\n",
       "          [2.9119e-09, 2.8007e-09, 2.2022e-09,  ..., 2.0726e-09,\n",
       "           2.6026e-09, 2.8866e-09],\n",
       "          [1.9989e-09, 2.6221e-09, 2.3464e-09,  ..., 2.3666e-09,\n",
       "           1.8025e-09, 2.4345e-09],\n",
       "          ...,\n",
       "          [2.2161e-09, 2.8804e-09, 2.8296e-09,  ..., 2.5045e-09,\n",
       "           2.4626e-09, 2.1494e-09],\n",
       "          [2.3207e-09, 1.9858e-09, 2.7349e-09,  ..., 2.4113e-09,\n",
       "           1.6213e-09, 2.3703e-09],\n",
       "          [2.3373e-09, 2.7344e-09, 1.7278e-09,  ..., 2.6932e-09,\n",
       "           2.1914e-09, 2.9468e-09]],\n",
       " \n",
       "         [[2.1998e-09, 2.1319e-09, 2.2078e-09,  ..., 2.2209e-09,\n",
       "           2.4936e-09, 1.5738e-09],\n",
       "          [2.5458e-09, 2.4040e-09, 2.0920e-09,  ..., 1.8440e-09,\n",
       "           2.3616e-09, 2.5607e-09],\n",
       "          [1.8538e-09, 2.2624e-09, 2.1780e-09,  ..., 2.1345e-09,\n",
       "           2.2177e-09, 1.9307e-09],\n",
       "          ...,\n",
       "          [1.5199e-09, 2.4688e-09, 2.3271e-09,  ..., 2.6445e-09,\n",
       "           1.6298e-09, 1.9615e-09],\n",
       "          [2.2918e-09, 2.1169e-09, 2.5771e-09,  ..., 1.3265e-09,\n",
       "           1.9876e-09, 2.1728e-09],\n",
       "          [1.8379e-09, 2.3218e-09, 1.4336e-09,  ..., 2.5953e-09,\n",
       "           2.3608e-09, 2.6053e-09]],\n",
       " \n",
       "         [[1.0175e-09, 1.5600e-09, 1.5791e-09,  ..., 1.1957e-09,\n",
       "           1.8909e-09, 1.8686e-09],\n",
       "          [1.6995e-09, 1.3169e-09, 1.4052e-09,  ..., 9.0686e-10,\n",
       "           1.5563e-09, 1.7211e-09],\n",
       "          [8.5846e-10, 1.0921e-09, 1.6964e-09,  ..., 1.6430e-09,\n",
       "           1.7888e-09, 1.0355e-09],\n",
       "          ...,\n",
       "          [1.4554e-09, 1.7731e-09, 1.7220e-09,  ..., 1.8849e-09,\n",
       "           1.6357e-09, 1.0941e-09],\n",
       "          [1.3411e-09, 1.5392e-09, 1.7503e-09,  ..., 1.1219e-09,\n",
       "           1.5466e-09, 1.0745e-09],\n",
       "          [1.3052e-09, 1.6628e-09, 9.9951e-10,  ..., 1.7674e-09,\n",
       "           1.4114e-09, 1.9040e-09]]], device='cuda:0'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SpikingJelly\n",
    "x.grad=None\n",
    "v=None\n",
    "out=None\n",
    "torch.cuda.reset_accumulated_memory_stats()\n",
    "from spikingjelly.activation_based import (\n",
    "    neuron as snn,\n",
    "    surrogate as sg,\n",
    "    functional as sf,\n",
    ")\n",
    "\n",
    "step_mode = \"m\"\n",
    "lif = snn.LIFNode(\n",
    "    surrogate_function=sg.Sigmoid(alpha=1.0), step_mode=step_mode, v_reset=0.0\n",
    ").to(device)\n",
    "if step_mode == \"m\":\n",
    "    sf.set_backend(lif, \"cupy\")\n",
    "\n",
    "\n",
    "def run():\n",
    "    global out\n",
    "    lif.reset()\n",
    "    x.grad = None\n",
    "    if step_mode == \"m\":\n",
    "        out = lif(x)\n",
    "    else:\n",
    "        out = []\n",
    "        for xt in x:\n",
    "            out += [lif(xt)]\n",
    "        out = torch.stack(out)\n",
    "    out.mean().backward()\n",
    "\n",
    "\n",
    "result = timeit.timeit(run, number=runs)\n",
    "result / runs, torch.cuda.max_memory_allocated() / 1024**2, out, x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23552153757998895,\n",
       " 1754.0009765625,\n",
       " tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 1., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
       "        grad_fn=<StackBackward0>),\n",
       " tensor([[[3.1360e-09, 2.8077e-09, 2.5562e-09,  ..., 2.7169e-09,\n",
       "           3.0387e-09, 2.0592e-09],\n",
       "          [3.1160e-09, 3.0047e-09, 2.8786e-09,  ..., 3.0577e-09,\n",
       "           1.9832e-09, 2.6103e-09],\n",
       "          [2.3786e-09, 2.9267e-09, 2.4821e-09,  ..., 2.9439e-09,\n",
       "           2.5631e-09, 2.9556e-09],\n",
       "          ...,\n",
       "          [3.1675e-09, 2.1269e-09, 2.5574e-09,  ..., 2.4270e-09,\n",
       "           3.1072e-09, 2.4845e-09],\n",
       "          [2.3759e-09, 2.7902e-09, 3.0947e-09,  ..., 3.1698e-09,\n",
       "           1.6019e-09, 2.5125e-09],\n",
       "          [3.1447e-09, 3.1090e-09, 2.6777e-09,  ..., 2.6627e-09,\n",
       "           2.6654e-09, 2.4354e-09]],\n",
       " \n",
       "         [[3.0872e-09, 2.3569e-09, 2.6355e-09,  ..., 2.6006e-09,\n",
       "           2.9799e-09, 2.1816e-09],\n",
       "          [3.0229e-09, 3.0921e-09, 2.4472e-09,  ..., 2.9002e-09,\n",
       "           1.7345e-09, 3.0452e-09],\n",
       "          [2.0980e-09, 2.7875e-09, 2.5615e-09,  ..., 3.1486e-09,\n",
       "           2.6264e-09, 2.6292e-09],\n",
       "          ...,\n",
       "          [3.1236e-09, 1.9840e-09, 2.3405e-09,  ..., 2.2916e-09,\n",
       "           3.0419e-09, 2.6505e-09],\n",
       "          [3.0147e-09, 2.8877e-09, 2.9543e-09,  ..., 3.1761e-09,\n",
       "           2.0924e-09, 2.8178e-09],\n",
       "          [3.1290e-09, 3.0431e-09, 2.4561e-09,  ..., 2.4742e-09,\n",
       "           1.9879e-09, 2.3073e-09]],\n",
       " \n",
       "         [[3.1450e-09, 2.7122e-09, 2.7430e-09,  ..., 2.0989e-09,\n",
       "           2.7199e-09, 2.1489e-09],\n",
       "          [2.7902e-09, 2.9779e-09, 1.4368e-09,  ..., 2.8764e-09,\n",
       "           1.9989e-09, 3.1720e-09],\n",
       "          [2.7123e-09, 3.0948e-09, 2.9400e-09,  ..., 3.0714e-09,\n",
       "           2.5694e-09, 2.8328e-09],\n",
       "          ...,\n",
       "          [3.0290e-09, 2.4213e-09, 2.5195e-09,  ..., 2.2456e-09,\n",
       "           2.8770e-09, 3.0628e-09],\n",
       "          [3.1308e-09, 2.9528e-09, 3.0399e-09,  ..., 3.1478e-09,\n",
       "           1.8815e-09, 2.4393e-09],\n",
       "          [3.0289e-09, 2.9487e-09, 2.4876e-09,  ..., 2.9311e-09,\n",
       "           2.5167e-09, 2.6904e-09]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[2.8896e-09, 2.3563e-09, 1.8637e-09,  ..., 2.4554e-09,\n",
       "           1.8630e-09, 2.5998e-09],\n",
       "          [2.5368e-09, 2.8691e-09, 1.1284e-09,  ..., 1.6113e-09,\n",
       "           2.3120e-09, 2.5020e-09],\n",
       "          [2.0586e-09, 2.4909e-09, 2.7101e-09,  ..., 2.5926e-09,\n",
       "           2.6615e-09, 1.9088e-09],\n",
       "          ...,\n",
       "          [2.5519e-09, 2.4852e-09, 2.4142e-09,  ..., 2.8551e-09,\n",
       "           2.6823e-09, 2.2006e-09],\n",
       "          [2.7607e-09, 2.9203e-09, 2.2195e-09,  ..., 1.3521e-09,\n",
       "           2.7836e-09, 2.2508e-09],\n",
       "          [2.7803e-09, 2.5094e-09, 2.4749e-09,  ..., 2.7808e-09,\n",
       "           2.9292e-09, 2.7548e-09]],\n",
       " \n",
       "         [[2.4774e-09, 2.0597e-09, 2.4261e-09,  ..., 2.4445e-09,\n",
       "           1.6770e-09, 2.0474e-09],\n",
       "          [2.4257e-09, 2.4376e-09, 1.1509e-09,  ..., 1.9662e-09,\n",
       "           2.1926e-09, 1.6592e-09],\n",
       "          [1.7264e-09, 1.7796e-09, 2.1977e-09,  ..., 2.4755e-09,\n",
       "           1.9988e-09, 1.6688e-09],\n",
       "          ...,\n",
       "          [1.6794e-09, 1.9992e-09, 1.8761e-09,  ..., 2.3880e-09,\n",
       "           2.4577e-09, 1.5428e-09],\n",
       "          [2.3310e-09, 2.5408e-09, 1.2588e-09,  ..., 1.3446e-09,\n",
       "           2.3291e-09, 2.5337e-09],\n",
       "          [2.2222e-09, 1.5683e-09, 2.5307e-09,  ..., 2.3780e-09,\n",
       "           2.6282e-09, 2.2324e-09]],\n",
       " \n",
       "         [[1.6085e-09, 1.5279e-09, 1.8410e-09,  ..., 1.6516e-09,\n",
       "           1.1577e-09, 1.4329e-09],\n",
       "          [1.3920e-09, 1.5562e-09, 1.1355e-09,  ..., 1.4545e-09,\n",
       "           1.0764e-09, 1.7346e-09],\n",
       "          [1.1384e-09, 1.4341e-09, 1.2656e-09,  ..., 1.5222e-09,\n",
       "           9.1443e-10, 1.4643e-09],\n",
       "          ...,\n",
       "          [1.7297e-09, 9.3476e-10, 9.0398e-10,  ..., 1.8366e-09,\n",
       "           1.6057e-09, 7.8876e-10],\n",
       "          [1.4661e-09, 1.8015e-09, 8.7234e-10,  ..., 1.0607e-09,\n",
       "           1.8982e-09, 1.6301e-09],\n",
       "          [1.4079e-09, 1.2038e-09, 1.6774e-09,  ..., 1.3825e-09,\n",
       "           1.9029e-09, 1.5728e-09]]], device='cuda:0'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchspike import LIF\n",
    "x.grad=None\n",
    "v=None\n",
    "out=None\n",
    "torch.cuda.reset_accumulated_memory_stats()\n",
    "\n",
    "lif = LIF.apply\n",
    "th = torch.tensor(1.0)\n",
    "tau = torch.tensor(2)\n",
    "\n",
    "\n",
    "def run():\n",
    "    global out\n",
    "    v = torch.zeros_like(x[0])\n",
    "    x.grad = None\n",
    "    v.grad = None\n",
    "    out = []\n",
    "    for xt in x:\n",
    "        xt, v = lif(xt, v, th, tau)\n",
    "        out += [xt]\n",
    "    out = torch.stack(out)\n",
    "    out.mean().backward()\n",
    "\n",
    "\n",
    "result = timeit.timeit(run, number=runs)\n",
    "result / runs, torch.cuda.max_memory_allocated() / 1024**2, out, x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21837792891999924,\n",
       " 2254.5009765625,\n",
       " tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 1., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
       "        grad_fn=<StackBackward0>),\n",
       " tensor([[[3.1360e-09, 2.8077e-09, 2.5562e-09,  ..., 2.7169e-09,\n",
       "           3.0387e-09, 2.0592e-09],\n",
       "          [3.1160e-09, 3.0047e-09, 2.8786e-09,  ..., 3.0577e-09,\n",
       "           1.9832e-09, 2.6103e-09],\n",
       "          [2.3786e-09, 2.9267e-09, 2.4821e-09,  ..., 2.9439e-09,\n",
       "           2.5631e-09, 2.9556e-09],\n",
       "          ...,\n",
       "          [3.1675e-09, 2.1269e-09, 2.5574e-09,  ..., 2.4270e-09,\n",
       "           3.1072e-09, 2.4845e-09],\n",
       "          [2.3759e-09, 2.7902e-09, 3.0947e-09,  ..., 3.1698e-09,\n",
       "           1.6019e-09, 2.5125e-09],\n",
       "          [3.1447e-09, 3.1090e-09, 2.6777e-09,  ..., 2.6627e-09,\n",
       "           2.6654e-09, 2.4354e-09]],\n",
       " \n",
       "         [[3.0872e-09, 2.3569e-09, 2.6355e-09,  ..., 2.6006e-09,\n",
       "           2.9799e-09, 2.1816e-09],\n",
       "          [3.0229e-09, 3.0921e-09, 2.4472e-09,  ..., 2.9002e-09,\n",
       "           1.7345e-09, 3.0452e-09],\n",
       "          [2.0980e-09, 2.7875e-09, 2.5615e-09,  ..., 3.1486e-09,\n",
       "           2.6264e-09, 2.6292e-09],\n",
       "          ...,\n",
       "          [3.1236e-09, 1.9840e-09, 2.3405e-09,  ..., 2.2916e-09,\n",
       "           3.0419e-09, 2.6505e-09],\n",
       "          [3.0147e-09, 2.8877e-09, 2.9543e-09,  ..., 3.1761e-09,\n",
       "           2.0924e-09, 2.8178e-09],\n",
       "          [3.1290e-09, 3.0431e-09, 2.4561e-09,  ..., 2.4742e-09,\n",
       "           1.9879e-09, 2.3073e-09]],\n",
       " \n",
       "         [[3.1450e-09, 2.7122e-09, 2.7430e-09,  ..., 2.0989e-09,\n",
       "           2.7199e-09, 2.1489e-09],\n",
       "          [2.7902e-09, 2.9779e-09, 1.4368e-09,  ..., 2.8764e-09,\n",
       "           1.9989e-09, 3.1720e-09],\n",
       "          [2.7123e-09, 3.0948e-09, 2.9400e-09,  ..., 3.0714e-09,\n",
       "           2.5694e-09, 2.8328e-09],\n",
       "          ...,\n",
       "          [3.0290e-09, 2.4213e-09, 2.5195e-09,  ..., 2.2456e-09,\n",
       "           2.8770e-09, 3.0628e-09],\n",
       "          [3.1308e-09, 2.9528e-09, 3.0399e-09,  ..., 3.1478e-09,\n",
       "           1.8815e-09, 2.4393e-09],\n",
       "          [3.0289e-09, 2.9487e-09, 2.4876e-09,  ..., 2.9311e-09,\n",
       "           2.5167e-09, 2.6904e-09]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[2.8896e-09, 2.3563e-09, 1.8637e-09,  ..., 2.4554e-09,\n",
       "           1.8630e-09, 2.5998e-09],\n",
       "          [2.5368e-09, 2.8691e-09, 1.1284e-09,  ..., 1.6113e-09,\n",
       "           2.3120e-09, 2.5020e-09],\n",
       "          [2.0586e-09, 2.4909e-09, 2.7101e-09,  ..., 2.5926e-09,\n",
       "           2.6615e-09, 1.9088e-09],\n",
       "          ...,\n",
       "          [2.5519e-09, 2.4852e-09, 2.4142e-09,  ..., 2.8551e-09,\n",
       "           2.6823e-09, 2.2006e-09],\n",
       "          [2.7607e-09, 2.9203e-09, 2.2195e-09,  ..., 1.3521e-09,\n",
       "           2.7836e-09, 2.2508e-09],\n",
       "          [2.7803e-09, 2.5094e-09, 2.4749e-09,  ..., 2.7808e-09,\n",
       "           2.9292e-09, 2.7548e-09]],\n",
       " \n",
       "         [[2.4774e-09, 2.0597e-09, 2.4261e-09,  ..., 2.4445e-09,\n",
       "           1.6770e-09, 2.0474e-09],\n",
       "          [2.4257e-09, 2.4376e-09, 1.1509e-09,  ..., 1.9662e-09,\n",
       "           2.1926e-09, 1.6592e-09],\n",
       "          [1.7264e-09, 1.7796e-09, 2.1977e-09,  ..., 2.4755e-09,\n",
       "           1.9988e-09, 1.6688e-09],\n",
       "          ...,\n",
       "          [1.6794e-09, 1.9992e-09, 1.8761e-09,  ..., 2.3880e-09,\n",
       "           2.4577e-09, 1.5428e-09],\n",
       "          [2.3310e-09, 2.5408e-09, 1.2588e-09,  ..., 1.3446e-09,\n",
       "           2.3291e-09, 2.5337e-09],\n",
       "          [2.2222e-09, 1.5683e-09, 2.5307e-09,  ..., 2.3780e-09,\n",
       "           2.6282e-09, 2.2324e-09]],\n",
       " \n",
       "         [[1.6085e-09, 1.5279e-09, 1.8410e-09,  ..., 1.6516e-09,\n",
       "           1.1577e-09, 1.4329e-09],\n",
       "          [1.3920e-09, 1.5562e-09, 1.1355e-09,  ..., 1.4545e-09,\n",
       "           1.0764e-09, 1.7346e-09],\n",
       "          [1.1384e-09, 1.4341e-09, 1.2656e-09,  ..., 1.5222e-09,\n",
       "           9.1443e-10, 1.4643e-09],\n",
       "          ...,\n",
       "          [1.7297e-09, 9.3476e-10, 9.0398e-10,  ..., 1.8366e-09,\n",
       "           1.6057e-09, 7.8876e-10],\n",
       "          [1.4661e-09, 1.8015e-09, 8.7234e-10,  ..., 1.0607e-09,\n",
       "           1.8982e-09, 1.6301e-09],\n",
       "          [1.4079e-09, 1.2038e-09, 1.6774e-09,  ..., 1.3825e-09,\n",
       "           1.9029e-09, 1.5728e-09]]], device='cuda:0'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchspike import LIF_CPP\n",
    "x.grad=None\n",
    "v=None\n",
    "out=None\n",
    "torch.cuda.reset_accumulated_memory_stats()\n",
    "\n",
    "lif = LIF_CPP.apply\n",
    "th = torch.tensor(1.0)\n",
    "tau = torch.tensor(2)\n",
    "\n",
    "\n",
    "def run():\n",
    "    global out\n",
    "    v = torch.zeros_like(x[0])\n",
    "    x.grad = None\n",
    "    v.grad = None\n",
    "    out = []\n",
    "    for xt in x:\n",
    "        xt, v = lif(xt, v, th, tau)\n",
    "        out += [xt]\n",
    "    out = torch.stack(out)\n",
    "    out.mean().backward()\n",
    "\n",
    "\n",
    "result = timeit.timeit(run, number=runs)\n",
    "result / runs, torch.cuda.max_memory_allocated() / 1024**2, out, x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14886225096001,\n",
       " 2501.0009765625,\n",
       " tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
       "        grad_fn=<StackBackward0>),\n",
       " tensor([[[3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09],\n",
       "          [3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09],\n",
       "          [3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09],\n",
       "          ...,\n",
       "          [3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09],\n",
       "          [3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09],\n",
       "          [3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09]],\n",
       " \n",
       "         [[3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09],\n",
       "          [3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09],\n",
       "          [3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09],\n",
       "          ...,\n",
       "          [3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09],\n",
       "          [3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09],\n",
       "          [3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09]],\n",
       " \n",
       "         [[3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09],\n",
       "          [3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09],\n",
       "          [3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09],\n",
       "          ...,\n",
       "          [3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09],\n",
       "          [3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09],\n",
       "          [3.0001e-09, 3.0001e-09, 3.0001e-09,  ..., 3.0001e-09,\n",
       "           3.0001e-09, 3.0001e-09]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[2.6251e-09, 2.6251e-09, 2.6251e-09,  ..., 2.6251e-09,\n",
       "           2.6251e-09, 2.6251e-09],\n",
       "          [2.6251e-09, 2.6251e-09, 2.6251e-09,  ..., 2.6251e-09,\n",
       "           2.6251e-09, 2.6251e-09],\n",
       "          [2.6251e-09, 2.6251e-09, 2.6251e-09,  ..., 2.6251e-09,\n",
       "           2.6251e-09, 2.6251e-09],\n",
       "          ...,\n",
       "          [2.6251e-09, 2.6251e-09, 2.6251e-09,  ..., 2.6251e-09,\n",
       "           2.6251e-09, 2.6251e-09],\n",
       "          [2.6251e-09, 2.6251e-09, 2.6251e-09,  ..., 2.6251e-09,\n",
       "           2.6251e-09, 2.6251e-09],\n",
       "          [2.6251e-09, 2.6251e-09, 2.6251e-09,  ..., 2.6251e-09,\n",
       "           2.6251e-09, 2.6251e-09]],\n",
       " \n",
       "         [[2.2500e-09, 2.2500e-09, 2.2500e-09,  ..., 2.2500e-09,\n",
       "           2.2500e-09, 2.2500e-09],\n",
       "          [2.2500e-09, 2.2500e-09, 2.2500e-09,  ..., 2.2500e-09,\n",
       "           2.2500e-09, 2.2500e-09],\n",
       "          [2.2500e-09, 2.2500e-09, 2.2500e-09,  ..., 2.2500e-09,\n",
       "           2.2500e-09, 2.2500e-09],\n",
       "          ...,\n",
       "          [2.2500e-09, 2.2500e-09, 2.2500e-09,  ..., 2.2500e-09,\n",
       "           2.2500e-09, 2.2500e-09],\n",
       "          [2.2500e-09, 2.2500e-09, 2.2500e-09,  ..., 2.2500e-09,\n",
       "           2.2500e-09, 2.2500e-09],\n",
       "          [2.2500e-09, 2.2500e-09, 2.2500e-09,  ..., 2.2500e-09,\n",
       "           2.2500e-09, 2.2500e-09]],\n",
       " \n",
       "         [[1.5000e-09, 1.5000e-09, 1.5000e-09,  ..., 1.5000e-09,\n",
       "           1.5000e-09, 1.5000e-09],\n",
       "          [1.5000e-09, 1.5000e-09, 1.5000e-09,  ..., 1.5000e-09,\n",
       "           1.5000e-09, 1.5000e-09],\n",
       "          [1.5000e-09, 1.5000e-09, 1.5000e-09,  ..., 1.5000e-09,\n",
       "           1.5000e-09, 1.5000e-09],\n",
       "          ...,\n",
       "          [1.5000e-09, 1.5000e-09, 1.5000e-09,  ..., 1.5000e-09,\n",
       "           1.5000e-09, 1.5000e-09],\n",
       "          [1.5000e-09, 1.5000e-09, 1.5000e-09,  ..., 1.5000e-09,\n",
       "           1.5000e-09, 1.5000e-09],\n",
       "          [1.5000e-09, 1.5000e-09, 1.5000e-09,  ..., 1.5000e-09,\n",
       "           1.5000e-09, 1.5000e-09]]], device='cuda:0'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchspike import LIF_CUDA\n",
    "x.grad=None\n",
    "v=None\n",
    "out=None\n",
    "torch.cuda.reset_accumulated_memory_stats()\n",
    "\n",
    "lif = LIF_CUDA.apply\n",
    "th =torch.tensor(1.0)\n",
    "tau = torch.tensor(2.0)\n",
    "\n",
    "\n",
    "def run():\n",
    "    global out\n",
    "    v = torch.zeros_like(x[0])\n",
    "    x.grad = None\n",
    "    v.grad = None\n",
    "    out = []\n",
    "    for xt in x:\n",
    "        xt, v = lif(xt, v, th, tau)\n",
    "        out += [xt]\n",
    "    out = torch.stack(out)\n",
    "    out.mean().backward()\n",
    "\n",
    "\n",
    "result = timeit.timeit(run, number=runs)\n",
    "result / runs, torch.cuda.max_memory_allocated() / 1024**2, out, x.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
